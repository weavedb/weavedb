import BigBuffer from "./bigbuffer.js"

export default function buildBatchConvert(tm, fnName, sIn, sOut) {
  return async function batchConvert(buffIn) {
    const nPoints = Math.floor(buffIn.byteLength / sIn)
    if (nPoints * sIn !== buffIn.byteLength) {
      throw new Error("Invalid buffer size")
    }
    const pointsPerChunk = Math.floor(nPoints / tm.concurrency)
    const opPromises = []
    for (let i = 0; i < tm.concurrency; i++) {
      let n
      if (i < tm.concurrency - 1) {
        n = pointsPerChunk
      } else {
        n = nPoints - i * pointsPerChunk
      }
      if (n == 0) continue

      const buffChunk = buffIn.slice(
        i * pointsPerChunk * sIn,
        i * pointsPerChunk * sIn + n * sIn
      )
      const task = [
        { cmd: "ALLOCSET", var: 0, buff: buffChunk },
        { cmd: "ALLOC", var: 1, len: sOut * n },
        {
          cmd: "CALL",
          fnName: fnName,
          params: [{ var: 0 }, { val: n }, { var: 1 }],
        },
        { cmd: "GET", out: 0, var: 1, len: sOut * n },
      ]
      opPromises.push(tm.queueAction(task))
    }

    const result = await Promise.all(opPromises)

    let fullBuffOut
    if (buffIn instanceof BigBuffer) {
      fullBuffOut = new BigBuffer(nPoints * sOut)
    } else {
      fullBuffOut = new Uint8Array(nPoints * sOut)
    }

    let p = 0
    for (let i = 0; i < result.length; i++) {
      fullBuffOut.set(result[i][0], p)
      p += result[i][0].byteLength
    }

    return fullBuffOut
  }
}
